
@misc{taylor_galactica_2022,
	title = {Galactica: {A} {Large} {Language} {Model} for {Science}},
	shorttitle = {Galactica},
	url = {http://arxiv.org/abs/2211.09085},
	abstract = {Information overload is a major obstacle to scientific progress. The explosive growth in scientific literature and data has made it ever harder to discover useful insights in a large mass of information. Today scientific knowledge is accessed through search engines, but they are unable to organize scientific knowledge alone. In this paper we introduce Galactica: a large language model that can store, combine and reason about scientific knowledge. We train on a large scientific corpus of papers, reference material, knowledge bases and many other sources. We outperform existing models on a range of scientific tasks. On technical knowledge probes such as LaTeX equations, Galactica outperforms the latest GPT-3 by 68.2\% versus 49.0\%. Galactica also performs well on reasoning, outperforming Chinchilla on mathematical MMLU by 41.3\% to 35.7\%, and PaLM 540B on MATH with a score of 20.4\% versus 8.8\%. It also sets a new state-of-the-art on downstream tasks such as PubMedQA and MedMCQA dev of 77.6\% and 52.9\%. And despite not being trained on a general corpus, Galactica outperforms BLOOM and OPT-175B on BIG-bench. We believe these results demonstrate the potential for language models as a new interface for science. We open source the model for the benefit of the scientific community.},
	urldate = {2023-12-05},
	publisher = {arXiv},
	author = {Taylor, Ross and Kardas, Marcin and Cucurull, Guillem and Scialom, Thomas and Hartshorn, Anthony and Saravia, Elvis and Poulton, Andrew and Kerkez, Viktor and Stojnic, Robert},
	month = nov,
	year = {2022},
	note = {arXiv:2211.09085 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\Thiago\\Zotero\\storage\\3NMFYMZC\\2211.html:text/html;Full Text PDF:C\:\\Users\\Thiago\\Zotero\\storage\\FPFHNFVF\\Taylor et al. - 2022 - Galactica A Large Language Model for Science.pdf:application/pdf},
}
